"""
ä¸¦åˆ—å®Ÿè¡Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è¤‡æ•°ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œãƒ­ã‚°ã‚’ç”Ÿæˆã—ã¦çµ±è¨ˆåˆ†æã‚’è¡Œã†
"""

import os
import time
import random
import threading
import json
from concurrent.futures import ThreadPoolExecutor
from tests.time_tracker import start_tracking, track, finish_tracking
from tests.performance_analyzer import PerformanceAnalyzer


def simulate_test_execution(test_id: int, base_delay: float = 0.1):
    """
    ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    
    Args:
        test_id: ãƒ†ã‚¹ãƒˆID
        base_delay: åŸºæœ¬é…å»¶æ™‚é–“
    """
    test_name = f"parallel_test_{test_id}"
    
    # æ¸¬å®šé–‹å§‹
    start_tracking(test_name)
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚¹ãƒ†ãƒƒãƒ—
    steps = [
        ("initialization", "åˆæœŸåŒ–å‡¦ç†", 0.05),
        ("page_load", "ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿", 0.1),
        ("user_interaction", "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œ", 0.08),
        ("data_validation", "ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼", 0.03),
        ("cleanup", "ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—", 0.02)
    ]
    
    for step_name, step_desc, step_delay in steps:
        track(step_name, step_desc)
        
        # ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰å‹•ã‚’åŠ ãˆã¦å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        actual_delay = base_delay + step_delay + random.uniform(-0.02, 0.05)
        time.sleep(max(0.01, actual_delay))  # æœ€ä½10ms
    
    # æ¸¬å®šçµ‚äº†
    summary = finish_tracking(test_name)
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆ{test_id}å®Œäº† - å®Ÿè¡Œæ™‚é–“: {summary['total_execution_time']:.3f}ç§’")
    return summary


def run_parallel_tests(num_tests: int = 5, num_threads: int = 3):
    """
    ä¸¦åˆ—ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    
    Args:
        num_tests: ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå›æ•°
        num_threads: ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°
    """
    print(f"ğŸš€ ä¸¦åˆ—ãƒ†ã‚¹ãƒˆé–‹å§‹: {num_tests}å›ã®ãƒ†ã‚¹ãƒˆã‚’{num_threads}ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢
    log_dir = "performance_logs"
    if os.path.exists(log_dir):
        for file in os.listdir(log_dir):
            if file.startswith("execution_"):
                os.remove(os.path.join(log_dir, file))
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = []
        
        for i in range(num_tests):
            # ãƒ†ã‚¹ãƒˆã”ã¨ã«ç•°ãªã‚‹åŸºæœ¬é…å»¶ã‚’è¨­å®š
            base_delay = random.uniform(0.05, 0.15)
            future = executor.submit(simulate_test_execution, i + 1, base_delay)
            futures.append(future)
        
        # å…¨ãƒ†ã‚¹ãƒˆã®å®Œäº†ã‚’å¾…æ©Ÿ
        results = []
        for future in futures:
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆå®Œäº†: {len(results)}ä»¶ã®ãƒ†ã‚¹ãƒˆãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
    return results


def analyze_results():
    """ä¸¦åˆ—å®Ÿè¡Œçµæœã‚’åˆ†æ"""
    print("\\nğŸ“Š çµæœåˆ†æä¸­...")
    
    analyzer = PerformanceAnalyzer()
    
    # ä¸¦åˆ—å®Ÿè¡Œãƒ­ã‚°ã‚’åˆ†æ
    analysis_result = analyzer.analyze_parallel_execution_logs("performance_logs")
    
    if analysis_result:
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¨è¡¨ç¤º
        report = analyzer.generate_parallel_analysis_report(analysis_result)
        print(report)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        json_path, report_path = analyzer.save_parallel_analysis(analysis_result)
        
        return analysis_result
    else:
        print("âŒ åˆ†æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return None


if __name__ == "__main__":
    print("ğŸ¯ ä¸¦åˆ—å®Ÿè¡Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ‡ãƒ¢")
    print("-" * 50)
    
    # åŸºæœ¬çš„ãªä¸¦åˆ—å®Ÿè¡Œãƒ‡ãƒ¢
    print("\\n1ï¸âƒ£ åŸºæœ¬çš„ãªä¸¦åˆ—å®Ÿè¡Œãƒ‡ãƒ¢")
    run_parallel_tests(6, 3)
    analyze_results()
    
    print("\\nâœ¨ ãƒ‡ãƒ¢å®Œäº†!")
    print("   performance_logs/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«è©³ç´°ãªåˆ†æçµæœãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")
